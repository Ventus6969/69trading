#!/usr/bin/env python3
"""
MLç‹€æ…‹ç›£æ§ç¨‹å¼
ç”¨æ–¼æŸ¥çœ‹69äº¤æ˜“æ©Ÿå™¨äººçš„MLç³»çµ±ç•¶å‰ç‹€æ…‹ä¸¦æª¢æ¸¬ç•°å¸¸æƒ…æ³
"""

import os
import sys
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import json
from tabulate import tabulate

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from database.ml_data_manager import MLDataManager, create_ml_data_manager
from database import get_database_path
from shadow_decision_engine import shadow_decision_engine, ML_AVAILABLE
from utils.logger_config import get_logger

logger = get_logger(__name__)

class MLStatusMonitor:
    """MLç‹€æ…‹ç›£æ§å™¨"""
    
    def __init__(self):
        db_path = get_database_path()
        self.ml_manager = create_ml_data_manager(db_path)
        
    def display_ml_overview(self):
        """é¡¯ç¤ºMLç³»çµ±ç¸½è¦½"""
        print("=" * 60)
        print("ğŸ¤– 69äº¤æ˜“æ©Ÿå™¨äºº MLç³»çµ±ç‹€æ…‹ç›£æ§")
        print("=" * 60)
        
        # MLå¯ç”¨æ€§ç‹€æ…‹
        ml_status = "âœ… å•Ÿç”¨" if ML_AVAILABLE else "âŒ æœªå•Ÿç”¨"
        print(f"MLç³»çµ±ç‹€æ…‹: {ml_status}")
        
        # ç²å–åŸºæœ¬çµ±è¨ˆ
        stats = self.ml_manager.get_ml_table_stats()
        
        print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
        print(f"  â€¢ MLç‰¹å¾µè¨˜éŒ„: {stats.get('total_ml_features', 0):,} ç­†")
        print(f"  â€¢ MLæ±ºç­–è¨˜éŒ„: {stats.get('total_ml_decisions', 0):,} ç­†") 
        print(f"  â€¢ åƒ¹æ ¼å„ªåŒ–è¨˜éŒ„: {stats.get('total_price_optimizations', 0):,} ç­†")
        
    def display_feature_statistics(self):
        """é¡¯ç¤ºç‰¹å¾µçµ±è¨ˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ MLç‰¹å¾µçµ±è¨ˆ")
        print("=" * 60)
        
        feature_stats = self.ml_manager.get_feature_statistics()
        
        if feature_stats:
            print(f"ç¸½ç‰¹å¾µæ•¸é‡: {feature_stats.get('total_features', 0):,}")
            print(f"å¹³å‡å‹ç‡: {feature_stats.get('avg_win_rate', 0):.2%}")
            print(f"å¹³å‡é¢¨éšªå›å ±æ¯”: {feature_stats.get('avg_risk_reward', 0):.2f}")
            print(f"å¹³å‡ä¿¡å¿ƒåˆ†æ•¸: {feature_stats.get('avg_confidence', 0):.2f}")
        else:
            print("æš«ç„¡ç‰¹å¾µçµ±è¨ˆæ•¸æ“š")
    
    def display_recent_decisions(self, limit: int = 10):
        """é¡¯ç¤ºæœ€è¿‘çš„MLæ±ºç­–"""
        print("\n" + "=" * 60)
        print(f"ğŸ¯ æœ€è¿‘ {limit} ç­†MLæ±ºç­–")
        print("=" * 60)
        
        decisions = self.ml_manager.get_recent_ml_decisions(limit)
        
        if not decisions:
            print("æš«ç„¡MLæ±ºç­–è¨˜éŒ„")
            return
            
        # æº–å‚™è¡¨æ ¼æ•¸æ“š
        table_data = []
        headers = ["æ™‚é–“", "äº¤æ˜“å°", "ç­–ç•¥", "æ–¹å‘", "å°ˆå®¶ä¿¡å¿ƒ", "MLä¿¡å¿ƒ", "æœ€çµ‚æ±ºç­–"]
        
        for decision in decisions:
            created_at = decision.get('created_at', '')
            if created_at:
                # è½‰æ›æ™‚é–“æ ¼å¼
                try:
                    dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    time_str = dt.strftime('%m-%d %H:%M')
                except:
                    time_str = created_at[:16]
            else:
                time_str = "N/A"
                
            symbol = decision.get('symbol', 'N/A')
            signal_type = decision.get('signal_type', 'N/A')
            side = decision.get('side', 'N/A')
            expert_confidence = f"{decision.get('expert_confidence', 0):.2f}"
            ml_confidence = f"{decision.get('ml_confidence', 0):.2f}"
            final_decision = "åŸ·è¡Œ" if decision.get('final_decision') else "è·³é"
            
            table_data.append([
                time_str, symbol, signal_type, side, 
                expert_confidence, ml_confidence, final_decision
            ])
        
        print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def check_data_integrity(self) -> List[Dict[str, Any]]:
        """æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§"""
        issues = []
        
        try:
            with sqlite3.connect(self.ml_manager.db_path) as conn:
                cursor = conn.cursor()
                
                # 1. æª¢æŸ¥NULLå€¼æ•¸é‡
                cursor.execute('''
                    SELECT 
                        COUNT(*) as total_records,
                        SUM(CASE WHEN strategy_win_rate_recent IS NULL THEN 1 ELSE 0 END) as null_win_rate,
                        SUM(CASE WHEN signal_confidence_score IS NULL THEN 1 ELSE 0 END) as null_confidence,
                        SUM(CASE WHEN risk_reward_ratio IS NULL THEN 1 ELSE 0 END) as null_risk_reward,
                        SUM(CASE WHEN session_id IS NULL OR session_id = '' THEN 1 ELSE 0 END) as null_session_id
                    FROM ml_features_v2
                ''')
                
                result = cursor.fetchone()
                if result and result[0] > 0:
                    total, null_win_rate, null_confidence, null_risk_reward, null_session = result
                    
                    if null_win_rate > 0:
                        issues.append({
                            'type': 'NULL_VALUES',
                            'table': 'ml_features_v2',
                            'field': 'strategy_win_rate_recent',
                            'count': null_win_rate,
                            'severity': 'MEDIUM',
                            'description': f'{null_win_rate}/{total} è¨˜éŒ„çš„å‹ç‡ç‚ºç©ºå€¼'
                        })
                    
                    if null_confidence > 0:
                        issues.append({
                            'type': 'NULL_VALUES',
                            'table': 'ml_features_v2', 
                            'field': 'signal_confidence_score',
                            'count': null_confidence,
                            'severity': 'HIGH',
                            'description': f'{null_confidence}/{total} è¨˜éŒ„çš„ä¿¡å¿ƒåˆ†æ•¸ç‚ºç©ºå€¼'
                        })
                    
                    if null_session > 0:
                        issues.append({
                            'type': 'NULL_VALUES',
                            'table': 'ml_features_v2',
                            'field': 'session_id', 
                            'count': null_session,
                            'severity': 'HIGH',
                            'description': f'{null_session}/{total} è¨˜éŒ„çš„session_idç‚ºç©ºå€¼'
                        })
                
                # 2. æª¢æŸ¥ç•°å¸¸æ•¸å€¼ç¯„åœ
                cursor.execute('''
                    SELECT COUNT(*) FROM ml_features_v2 
                    WHERE strategy_win_rate_recent < 0 OR strategy_win_rate_recent > 1
                ''')
                invalid_win_rate = cursor.fetchone()[0]
                if invalid_win_rate > 0:
                    issues.append({
                        'type': 'INVALID_RANGE',
                        'table': 'ml_features_v2',
                        'field': 'strategy_win_rate_recent',
                        'count': invalid_win_rate,
                        'severity': 'HIGH',
                        'description': f'{invalid_win_rate} è¨˜éŒ„çš„å‹ç‡è¶…å‡ºæœ‰æ•ˆç¯„åœ [0,1]'
                    })
                
                # 3. æª¢æŸ¥å­¤ç«‹è¨˜éŒ„ (æœ‰ç‰¹å¾µä½†ç„¡æ±ºç­–)
                cursor.execute('''
                    SELECT COUNT(*) FROM ml_features_v2 f
                    LEFT JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    WHERE q.id IS NULL AND f.signal_id IS NOT NULL
                ''')
                orphaned_features = cursor.fetchone()[0]
                if orphaned_features > 0:
                    issues.append({
                        'type': 'ORPHANED_RECORD',
                        'table': 'ml_features_v2',
                        'field': 'signal_id',
                        'count': orphaned_features,
                        'severity': 'MEDIUM',
                        'description': f'{orphaned_features} ç‰¹å¾µè¨˜éŒ„æ²’æœ‰å°æ‡‰çš„æ±ºç­–è¨˜éŒ„'
                    })
                
                # 4. æª¢æŸ¥æœ€è¿‘è¨˜éŒ„æ™‚é–“
                cursor.execute('SELECT MAX(created_at) FROM ml_features_v2')
                last_feature_time = cursor.fetchone()[0]
                if last_feature_time:
                    try:
                        last_dt = datetime.fromisoformat(last_feature_time.replace('Z', '+00:00'))
                        time_diff = datetime.now() - last_dt
                        if time_diff.total_seconds() > 86400:  # 24å°æ™‚
                            issues.append({
                                'type': 'STALE_DATA',
                                'table': 'ml_features_v2',
                                'field': 'created_at',
                                'count': 1,
                                'severity': 'MEDIUM',
                                'description': f'æœ€å¾Œç‰¹å¾µè¨˜éŒ„æ™‚é–“: {last_feature_time} (è¶…é24å°æ™‚)'
                            })
                    except:
                        pass
                
        except Exception as e:
            issues.append({
                'type': 'DATABASE_ERROR',
                'table': 'unknown',
                'field': 'unknown',
                'count': 0,
                'severity': 'HIGH',
                'description': f'æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§æ™‚å‡ºéŒ¯: {str(e)}'
            })
        
        return issues
    
    def check_ml_training_data_quality(self) -> Dict[str, Any]:
        """æª¢æŸ¥MLè¨“ç·´æ•¸æ“šå“è³ª"""
        result = {
            'total_features': 0,
            'total_decisions': 0,
            'complete_training_pairs': 0,
            'training_ready_records': 0,
            'issues': []
        }
        
        try:
            with sqlite3.connect(self.ml_manager.db_path) as conn:
                cursor = conn.cursor()
                
                # 1. æª¢æŸ¥å®Œæ•´çš„è¨“ç·´æ•¸æ“šå° (ç‰¹å¾µ+æ±ºç­–+äº¤æ˜“çµæœ)
                cursor.execute('''
                    SELECT 
                        COUNT(*) as complete_pairs
                    FROM ml_features_v2 f
                    INNER JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    INNER JOIN orders_executed oe ON f.signal_id = oe.signal_id
                    INNER JOIN trading_results tr ON oe.id = tr.order_id
                    WHERE f.signal_id IS NOT NULL
                ''')
                
                complete_pairs = cursor.fetchone()[0]
                result['complete_training_pairs'] = complete_pairs
                
                # 2. æª¢æŸ¥ç‰¹å¾µ+æ±ºç­–å° (å³ä½¿æ²’æœ‰äº¤æ˜“çµæœ)
                cursor.execute('''
                    SELECT COUNT(*) 
                    FROM ml_features_v2 f
                    INNER JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    WHERE f.signal_id IS NOT NULL
                ''')
                
                feature_decision_pairs = cursor.fetchone()[0]
                result['feature_decision_pairs'] = feature_decision_pairs
                
                # 3. æª¢æŸ¥ç¼ºå¤±äº¤æ˜“çµæœçš„è¨˜éŒ„
                cursor.execute('''
                    SELECT COUNT(*) 
                    FROM ml_features_v2 f
                    INNER JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    INNER JOIN orders_executed oe ON f.signal_id = oe.signal_id
                    LEFT JOIN trading_results tr ON oe.id = tr.order_id
                    WHERE f.signal_id IS NOT NULL AND tr.id IS NULL
                ''')
                
                missing_results = cursor.fetchone()[0]
                result['missing_trading_results'] = missing_results
                
                # 4. çµ±è¨ˆå„ç­–ç•¥çš„å¯ç”¨è¨“ç·´æ•¸æ“š
                cursor.execute('''
                    SELECT 
                        sr.signal_type,
                        COUNT(*) as count
                    FROM ml_features_v2 f
                    INNER JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    INNER JOIN signals_received sr ON f.signal_id = sr.id
                    INNER JOIN orders_executed oe ON f.signal_id = oe.signal_id
                    INNER JOIN trading_results tr ON oe.id = tr.order_id
                    GROUP BY sr.signal_type
                    ORDER BY count DESC
                ''')
                
                strategy_stats = {}
                for row in cursor.fetchall():
                    strategy_stats[row[0]] = row[1]
                result['strategy_training_data'] = strategy_stats
                
                # 5. åˆ†ææ•¸æ“šå“è³ªå•é¡Œ
                if complete_pairs < 10:
                    result['issues'].append({
                        'type': 'INSUFFICIENT_TRAINING_DATA',
                        'severity': 'HIGH',
                        'description': f'å®Œæ•´è¨“ç·´æ•¸æ“šä¸è¶³: {complete_pairs}/50 (éœ€è¦è‡³å°‘50ç­†)'
                    })
                
                if missing_results > 0:
                    result['issues'].append({
                        'type': 'MISSING_TRADING_RESULTS', 
                        'severity': 'MEDIUM',
                        'description': f'{missing_results} ç­†äº¤æ˜“ç¼ºå°‘æœ€çµ‚çµæœè¨˜éŒ„ (å¯èƒ½æ˜¯æ‰‹å‹•æ“ä½œ)'
                    })
                
                # 6. æª¢æŸ¥ç‰¹å¾µå®Œæ•´æ€§
                cursor.execute('''
                    SELECT COUNT(*) FROM ml_features_v2
                    WHERE strategy_win_rate_recent = 0 
                    AND signal_confidence_score = 0
                    AND risk_reward_ratio = 0
                ''')
                
                zero_features = cursor.fetchone()[0]
                if zero_features > 0:
                    result['issues'].append({
                        'type': 'ZERO_VALUE_FEATURES',
                        'severity': 'MEDIUM', 
                        'description': f'{zero_features} ç­†è¨˜éŒ„çš„é—œéµç‰¹å¾µå€¼ç‚º0 (å¯èƒ½æ˜¯è¨ˆç®—å¤±æ•—)'
                    })
                
                result['training_ready_records'] = complete_pairs
                
        except Exception as e:
            result['issues'].append({
                'type': 'ANALYSIS_ERROR',
                'severity': 'HIGH',
                'description': f'MLè¨“ç·´æ•¸æ“šæª¢æŸ¥å‡ºéŒ¯: {str(e)}'
            })
        
        return result
    
    def check_ml_anomalies(self) -> List[Dict[str, Any]]:
        """æª¢æŸ¥MLç³»çµ±ç•°å¸¸"""
        anomalies = []
        
        try:
            with sqlite3.connect(self.ml_manager.db_path) as conn:
                cursor = conn.cursor()
                
                # 1. æª¢æŸ¥æ±ºç­–ä¸€è‡´æ€§ (ä½¿ç”¨ç¾æœ‰æ¬„ä½)
                cursor.execute('''
                    SELECT 
                        COUNT(*) as total,
                        AVG(confidence_score) as avg_confidence
                    FROM ml_signal_quality 
                    WHERE confidence_score IS NOT NULL
                    AND created_at > datetime('now', '-7 days')
                ''')
                
                result = cursor.fetchone()
                if result and result[0] > 0:
                    avg_confidence = result[1] or 0
                    if avg_confidence < 0.2:  # å¹³å‡ä¿¡å¿ƒåˆ†æ•¸éä½
                        anomalies.append({
                            'type': 'LOW_CONFIDENCE',
                            'severity': 'MEDIUM', 
                            'value': avg_confidence,
                            'description': f'æœ€è¿‘7å¤©å¹³å‡ä¿¡å¿ƒåˆ†æ•¸éä½: {avg_confidence:.3f}'
                        })
                
                # 2. æª¢æŸ¥å‹ç‡ç•°å¸¸
                cursor.execute('''
                    SELECT AVG(strategy_win_rate_recent) 
                    FROM ml_features_v2 
                    WHERE created_at > datetime('now', '-7 days')
                    AND strategy_win_rate_recent IS NOT NULL
                ''')
                
                result = cursor.fetchone()
                if result and result[0] is not None:
                    avg_win_rate = result[0]
                    if avg_win_rate < 0.3:  # å‹ç‡ä½æ–¼30%
                        anomalies.append({
                            'type': 'LOW_WIN_RATE',
                            'severity': 'HIGH',
                            'value': avg_win_rate,
                            'description': f'æœ€è¿‘7å¤©å¹³å‡å‹ç‡éä½: {avg_win_rate:.2%}'
                        })
                
                # 3. æª¢æŸ¥æ±ºç­–é »ç‡ç•°å¸¸
                cursor.execute('''
                    SELECT COUNT(*) FROM ml_signal_quality
                    WHERE created_at > datetime('now', '-24 hours')
                ''')
                
                decisions_24h = cursor.fetchone()[0]
                if decisions_24h == 0:
                    anomalies.append({
                        'type': 'NO_RECENT_DECISIONS',
                        'severity': 'HIGH',
                        'value': 0,
                        'description': 'éå»24å°æ™‚å…§æ²’æœ‰MLæ±ºç­–è¨˜éŒ„'
                    })
                elif decisions_24h > 100:  # ç•°å¸¸é«˜é »
                    anomalies.append({
                        'type': 'HIGH_FREQUENCY_DECISIONS',
                        'severity': 'MEDIUM',
                        'value': decisions_24h,
                        'description': f'éå»24å°æ™‚æ±ºç­–é »ç‡ç•°å¸¸é«˜: {decisions_24h} æ¬¡'
                    })
                
                # 4. æª¢æŸ¥ç‰¹å¾µå€¼åˆ†ä½ˆç•°å¸¸
                cursor.execute('''
                    SELECT 
                        AVG(signal_confidence_score) as avg_confidence,
                        MIN(signal_confidence_score) as min_confidence,
                        MAX(signal_confidence_score) as max_confidence
                    FROM ml_features_v2 
                    WHERE created_at > datetime('now', '-7 days')
                    AND signal_confidence_score IS NOT NULL
                ''')
                
                result = cursor.fetchone()
                if result:
                    avg_conf, min_conf, max_conf = result
                    if avg_conf and min_conf and max_conf:
                        if max_conf - min_conf < 0.1:  # è®Šç•°æ€§å¤ªå°
                            anomalies.append({
                                'type': 'LOW_FEATURE_VARIANCE',
                                'severity': 'MEDIUM', 
                                'value': max_conf - min_conf,
                                'description': f'ä¿¡å¿ƒåˆ†æ•¸è®Šç•°æ€§éä½: ç¯„åœ {min_conf:.3f} - {max_conf:.3f}'
                            })
                
        except Exception as e:
            anomalies.append({
                'type': 'ANALYSIS_ERROR',
                'severity': 'HIGH',
                'value': 0,
                'description': f'MLç•°å¸¸æª¢æŸ¥æ™‚å‡ºéŒ¯: {str(e)}'
            })
        
        return anomalies
    
    def display_ml_training_data_analysis(self):
        """é¡¯ç¤ºMLè¨“ç·´æ•¸æ“šåˆ†æ"""
        print("\n" + "=" * 60)
        print("ğŸ¯ MLè¨“ç·´æ•¸æ“šå“è³ªåˆ†æ")
        print("=" * 60)
        
        analysis = self.check_ml_training_data_quality()
        
        print(f"ğŸ“Š è¨“ç·´æ•¸æ“šçµ±è¨ˆ:")
        print(f"  â€¢ å®Œæ•´è¨“ç·´æ•¸æ“šå°: {analysis['complete_training_pairs']} ç­†")
        print(f"  â€¢ ç‰¹å¾µ+æ±ºç­–é…å°: {analysis['feature_decision_pairs']} ç­†") 
        print(f"  â€¢ ç¼ºå¤±äº¤æ˜“çµæœ: {analysis['missing_trading_results']} ç­†")
        
        # é¡¯ç¤ºå„ç­–ç•¥çš„è¨“ç·´æ•¸æ“š
        if analysis.get('strategy_training_data'):
            print(f"\nğŸ“ˆ å„ç­–ç•¥å®Œæ•´è¨“ç·´æ•¸æ“š:")
            for strategy, count in analysis['strategy_training_data'].items():
                print(f"  â€¢ {strategy}: {count} ç­†")
        else:
            print(f"\nğŸ“ˆ å„ç­–ç•¥å®Œæ•´è¨“ç·´æ•¸æ“š: æš«ç„¡")
        
        # é¡¯ç¤ºé€²åº¦
        progress = analysis['complete_training_pairs']
        target = 50
        progress_pct = (progress / target * 100) if target > 0 else 0
        print(f"\nğŸ¯ MLå•Ÿç”¨é€²åº¦: {progress}/{target} ç­† ({progress_pct:.1f}%)")
        
        # é¡¯ç¤ºå•é¡Œ
        if analysis['issues']:
            print(f"\nâš ï¸ è¨“ç·´æ•¸æ“šå•é¡Œ:")
            for issue in analysis['issues']:
                severity_icon = "ğŸš¨" if issue['severity'] == 'HIGH' else "ğŸŸ¡"
                print(f"  {severity_icon} {issue['description']}")
        else:
            print(f"\nâœ… è¨“ç·´æ•¸æ“šå“è³ªè‰¯å¥½")
    
    def display_missing_trading_results_details(self):
        """é¡¯ç¤ºç¼ºå¤±äº¤æ˜“çµæœçš„è©³ç´°ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ” ç¼ºå¤±äº¤æ˜“çµæœè©³ç´°åˆ†æ")
        print("=" * 60)
        
        try:
            with sqlite3.connect(self.ml_manager.db_path) as conn:
                cursor = conn.cursor()
                
                # æŸ¥æ‰¾æœ‰æ±ºç­–ä½†ç¼ºå¤±äº¤æ˜“çµæœçš„è¨˜éŒ„
                cursor.execute('''
                    SELECT 
                        sr.id as signal_id,
                        sr.symbol,
                        sr.signal_type,
                        sr.side,
                        sr.timestamp,
                        oe.client_order_id,
                        oe.binance_order_id,
                        oe.price as entry_price,
                        oe.quantity,
                        oe.tp_price,
                        oe.sl_price,
                        oe.status,
                        datetime(sr.timestamp, 'unixepoch') as signal_time,
                        datetime(oe.execution_timestamp, 'unixepoch') as execution_time
                    FROM ml_features_v2 f
                    INNER JOIN ml_signal_quality q ON f.signal_id = q.signal_id
                    INNER JOIN signals_received sr ON f.signal_id = sr.id
                    INNER JOIN orders_executed oe ON f.signal_id = oe.signal_id
                    LEFT JOIN trading_results tr ON oe.id = tr.order_id
                    WHERE f.signal_id IS NOT NULL AND tr.id IS NULL
                    ORDER BY sr.timestamp DESC
                ''')
                
                missing_orders = cursor.fetchall()
                
                if not missing_orders:
                    print("âœ… æ²’æœ‰ç™¼ç¾ç¼ºå¤±äº¤æ˜“çµæœçš„è¨‚å–®")
                    return
                
                print(f"ç™¼ç¾ {len(missing_orders)} ç­†ç¼ºå¤±äº¤æ˜“çµæœçš„è¨‚å–®ï¼š\n")
                
                headers = ["ä¿¡è™Ÿæ™‚é–“", "äº¤æ˜“å°", "ç­–ç•¥", "æ–¹å‘", "å®¢æˆ¶è¨‚å–®ID", "å¹£å®‰è¨‚å–®ID", "é–‹å€‰åƒ¹", "æ•¸é‡", "æ­¢ç›ˆåƒ¹", "ç‹€æ…‹"]
                table_data = []
                
                for order in missing_orders:
                    signal_id, symbol, signal_type, side, timestamp, client_order_id, binance_order_id, entry_price, quantity, tp_price, sl_price, status, signal_time, execution_time = order
                    
                    table_data.append([
                        signal_time[:16] if signal_time else "N/A",
                        symbol or "N/A",
                        signal_type or "N/A", 
                        side or "N/A",
                        client_order_id or "N/A",
                        str(binance_order_id) if binance_order_id else "N/A",
                        f"{entry_price:.6f}" if entry_price else "N/A",
                        f"{quantity:.4f}" if quantity else "N/A",
                        f"{tp_price:.6f}" if tp_price else "N/A",
                        status or "N/A"
                    ])
                
                print(tabulate(table_data, headers=headers, tablefmt="grid"))
                
                # æä¾›æ¢å¾©å»ºè­°
                print(f"\nğŸ’¡ æ•¸æ“šæ¢å¾©å»ºè­°:")
                print(f"1. æª¢æŸ¥ä»¥ä¸‹å®¢æˆ¶è¨‚å–®IDçš„äº¤æ˜“è¨˜éŒ„:")
                for order in missing_orders:
                    client_order_id = order[5]
                    binance_order_id = order[6]
                    if client_order_id:
                        print(f"   â€¢ å®¢æˆ¶è¨‚å–®ID: {client_order_id}")
                    if binance_order_id:
                        print(f"     å¹£å®‰è¨‚å–®ID: {binance_order_id}")
                
                print(f"\n2. å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ¢å¾©æ•¸æ“š:")
                print(f"   â€¢ å¾äº¤æ˜“æ‰€APIæŸ¥è©¢è¨‚å–®æœ€çµ‚ç‹€æ…‹")
                print(f"   â€¢ æª¢æŸ¥ç³»çµ±æ—¥èªŒæ–‡ä»¶")
                print(f"   â€¢ æ‰‹å‹•èª¿ç”¨ record_trading_result_by_client_id() è£œå……çµæœ")
                
                # é¡¯ç¤ºSQLæ¢å¾©æ¨¡æ¿
                print(f"\n3. æ‰‹å‹•æ¢å¾©SQLæ¨¡æ¿:")
                print(f"   å¦‚æœçŸ¥é“äº¤æ˜“çµæœï¼Œå¯ä»¥ç›´æ¥æ’å…¥ trading_results è¡¨")
                
        except Exception as e:
            print(f"âŒ æŸ¥è©¢ç¼ºå¤±äº¤æ˜“çµæœæ™‚å‡ºéŒ¯: {e}")

    def display_data_health_check(self):
        """é¡¯ç¤ºæ•¸æ“šå¥åº·æª¢æŸ¥çµæœ"""
        print("\n" + "=" * 60)
        print("ğŸ” MLæ•¸æ“šå¥åº·æª¢æŸ¥")
        print("=" * 60)
        
        # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
        integrity_issues = self.check_data_integrity()
        
        # æª¢æŸ¥MLç•°å¸¸
        ml_anomalies = self.check_ml_anomalies()
        
        # åˆä½µæ‰€æœ‰å•é¡Œ
        all_issues = integrity_issues + ml_anomalies
        
        if not all_issues:
            print("âœ… æ•¸æ“šå¥åº·ç‹€æ³è‰¯å¥½ï¼Œæœªç™¼ç¾ç•°å¸¸")
            return
        
        # æŒ‰åš´é‡ç¨‹åº¦åˆ†é¡
        high_issues = [i for i in all_issues if i.get('severity') == 'HIGH']
        medium_issues = [i for i in all_issues if i.get('severity') == 'MEDIUM']
        
        if high_issues:
            print("ğŸš¨ é«˜åš´é‡åº¦å•é¡Œ:")
            for issue in high_issues:
                print(f"  âŒ {issue['description']}")
        
        if medium_issues:
            print("\nâš ï¸  ä¸­ç­‰åš´é‡åº¦å•é¡Œ:")
            for issue in medium_issues:
                print(f"  ğŸŸ¡ {issue['description']}")
        
        # é¡¯ç¤ºçµ±è¨ˆ
        print(f"\nğŸ“‹ å•é¡Œçµ±è¨ˆ: é«˜åš´é‡åº¦ {len(high_issues)} å€‹ï¼Œä¸­åš´é‡åº¦ {len(medium_issues)} å€‹")
    
    def display_database_info(self):
        """é¡¯ç¤ºè³‡æ–™åº«ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ’¾ è³‡æ–™åº«ä¿¡æ¯")
        print("=" * 60)
        
        db_path = self.ml_manager.db_path
        print(f"è³‡æ–™åº«è·¯å¾‘: {db_path}")
        
        if os.path.exists(db_path):
            # ç²å–æ–‡ä»¶å¤§å°
            size_mb = os.path.getsize(db_path) / (1024 * 1024)
            print(f"è³‡æ–™åº«å¤§å°: {size_mb:.2f} MB")
            
            # ç²å–ä¿®æ”¹æ™‚é–“
            mtime = os.path.getmtime(db_path)
            mtime_str = datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
            print(f"æœ€å¾Œä¿®æ”¹: {mtime_str}")
            
            # æª¢æŸ¥è¡¨æ ¼çµæ§‹
            try:
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                    tables = [row[0] for row in cursor.fetchall()]
                    print(f"è³‡æ–™è¡¨æ•¸é‡: {len(tables)}")
                    print(f"ä¸»è¦è¡¨æ ¼: {', '.join(tables[:5])}")
            except Exception as e:
                print(f"ç„¡æ³•è®€å–è¡¨æ ¼ä¿¡æ¯: {e}")
        else:
            print("âŒ è³‡æ–™åº«æ–‡ä»¶ä¸å­˜åœ¨")
    
    def display_shadow_engine_status(self):
        """é¡¯ç¤ºå½±å­æ±ºç­–å¼•æ“ç‹€æ…‹"""
        print("\n" + "=" * 60)
        print("ğŸ‘¤ å½±å­æ±ºç­–å¼•æ“ç‹€æ…‹")
        print("=" * 60)
        
        try:
            # æª¢æŸ¥å¼•æ“æ˜¯å¦å¯ç”¨
            if shadow_decision_engine:
                print("âœ… å½±å­æ±ºç­–å¼•æ“å·²åˆå§‹åŒ–")
                
                # ç²å–ç­–ç•¥é…ç½®
                if hasattr(shadow_decision_engine, 'strategy_configs'):
                    configs = shadow_decision_engine.strategy_configs
                    print(f"å·²é…ç½®ç­–ç•¥: {len(configs)} å€‹")
                    
                    # é¡¯ç¤ºéƒ¨åˆ†ç­–ç•¥é…ç½®
                    for strategy, config in list(configs.items())[:3]:
                        confidence = config.get('default_confidence', 0)
                        note = config.get('note', '')
                        print(f"  â€¢ {strategy}: ä¿¡å¿ƒåº¦ {confidence:.2f} - {note}")
                        
                    if len(configs) > 3:
                        print(f"  ... é‚„æœ‰ {len(configs) - 3} å€‹ç­–ç•¥")
                        
            else:
                print("âŒ å½±å­æ±ºç­–å¼•æ“æœªåˆå§‹åŒ–")
                
        except Exception as e:
            print(f"âŒ æª¢æŸ¥å½±å­æ±ºç­–å¼•æ“æ™‚å‡ºéŒ¯: {e}")
    
    def run_full_status_check(self):
        """åŸ·è¡Œå®Œæ•´ç‹€æ…‹æª¢æŸ¥"""
        try:
            self.display_ml_overview()
            self.display_feature_statistics() 
            self.display_recent_decisions()
            self.display_ml_training_data_analysis()  # æ–°å¢MLè¨“ç·´æ•¸æ“šåˆ†æ
            self.display_data_health_check()  # æ–°å¢å¥åº·æª¢æŸ¥
            self.display_shadow_engine_status()
            self.display_database_info()
            
            print("\n" + "=" * 60)
            print("âœ… MLç‹€æ…‹æª¢æŸ¥å®Œæˆ")
            print("=" * 60)
            
        except Exception as e:
            logger.error(f"åŸ·è¡Œç‹€æ…‹æª¢æŸ¥æ™‚å‡ºéŒ¯: {e}")
            print(f"âŒ ç‹€æ…‹æª¢æŸ¥å‡ºéŒ¯: {e}")

def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='69äº¤æ˜“æ©Ÿå™¨äºº MLç‹€æ…‹ç›£æ§')
    parser.add_argument('--recent', '-r', type=int, default=10, 
                       help='é¡¯ç¤ºæœ€è¿‘Nç­†MLæ±ºç­– (é è¨­: 10)')
    parser.add_argument('--overview', '-o', action='store_true', 
                       help='åªé¡¯ç¤ºç¸½è¦½')
    parser.add_argument('--stats', '-s', action='store_true',
                       help='åªé¡¯ç¤ºçµ±è¨ˆ')
    parser.add_argument('--health', '--check', action='store_true',
                       help='åªåŸ·è¡Œå¥åº·æª¢æŸ¥')
    parser.add_argument('--training', '-t', action='store_true',
                       help='åªé¡¯ç¤ºMLè¨“ç·´æ•¸æ“šåˆ†æ')
    parser.add_argument('--missing', '-m', action='store_true',
                       help='é¡¯ç¤ºç¼ºå¤±äº¤æ˜“çµæœçš„è©³ç´°ä¿¡æ¯')
    
    args = parser.parse_args()
    
    monitor = MLStatusMonitor()
    
    try:
        if args.overview:
            monitor.display_ml_overview()
        elif args.stats:
            monitor.display_feature_statistics()
        elif args.health:
            monitor.display_data_health_check()
        elif args.training:
            monitor.display_ml_training_data_analysis()
        elif args.missing:
            monitor.display_missing_trading_results_details()
        else:
            # é è¨­åŸ·è¡Œå®Œæ•´æª¢æŸ¥
            monitor.run_full_status_check()
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹å¼å·²ä¸­æ–·")
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå‡ºéŒ¯: {e}")
        logger.error(f"MLç‹€æ…‹ç›£æ§ç¨‹å¼å‡ºéŒ¯: {e}")

if __name__ == "__main__":
    main()